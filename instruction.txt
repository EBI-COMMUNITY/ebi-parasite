Task1: Trimming of the raw sequence                                                                                                                        
This is actually clear. We have developed a script that uses trim_galore to trim the raw sequences. Trim_galore is the default quality control program in this stage, but we can add some others in case we decide to use other programs. Please let me know if there is anything that you would prefer to use. 

Simone: No, I think any tool is good. I suppose that you can set various parameters before running the tool, which may be important if we decide, e.g., to remove reads of low quality 
Task 2: Assembly (ideally, tests of different assemblers and selection of the best)          	
Here we use spade and velvet. This work hasn’t been finished. But I think the instruction for this is clear to me. 

Simoen: Consider that my colleagues at University of Trento obtained good results using Spades, so I would suggest to use this assembler.

Nima: Sure we go for Spade with no other assembly pipeline, but they way we use it might be a bit different than the other team.
Simone: no problem, I trust you!


Task 3: Creating a parasite reference database

Question 1: Shall we create a database of all the SNPs for a parasites or specific parasite and then place the query genome SNPs against the pre calculated SNPs set to do the comparative analysis? If we want to include the publicly available datasets we should first find them, decide if we want to include them, and then perform SNPs for them and build a reference database for them. So any query genome shall be analysed against that database. Shall we include all the nominated parasites in one database and do the phylogenetics against that? Or one database per species? I would go for one reference database containing all the parasite genomes and compare all the incoming against that.
Simone: it depends on the analysis. I think that C. parvum genomes should be compared first with all other C. parvum genomes and then with C. hominis. Take into account that when we assessed (just before the summer) genome information in public database, we ended up with 4 relatively good C. parvum genomes and 6 less complete, and a slightly larger number for C. hominis. Thus, information to build a SNP database is still limited, but we have 22 C. parvum genomes we sequenced and shortly we will increase this number as well as that for C. hominis.
I agree to use all the information, I am not sure whether a single database is better than two. We can discuss pros and cons, if you wish

Nima: Would you provide the accessions list of all the genomes that you found in the public database? I also will ask my team member to create a list of all the available genomes and sequences in the database for C. parvum and C. hominis and pass it you, so you can check them and let me know if you wish to include any of them.
Simone: sure I will. 

Task 4: Reference mapping against annotated genomes (C. parvum and C. hominis), and calculation of standard parameters (e.g., coverage).
Question 1: Do we want to map the contigs or reads against the reference genomes?
Simone: Yes, I think that this is necessary for a number of things, including identification of core and accessory genes, 

Nima: OK great, shall we map the contigs we get from the assembly stage against the reference genome? Or map the raw reads against the reference genome? I guess you want to map reads!
Simone: well, we will surely map the reads, but to look for rearrangements, one can use MAUVE, and I think contigs

Question 2: What are the reference genomes? We need ENA accessions.
                C. parvum:?         	Study: PRJNA144        ASM16534v1 (IOWA strain)
Great this has the full assembly, contigs and chromosomes.
http://www.ebi.ac.uk/ena/data/view/PRJNA144
http://www.ebi.ac.uk/ena/data/view/GCA_000165345

                C. hominis:?	Study: PRJNA222836
This has WGS assembly:
http://www.ebi.ac.uk/ena/data/view/GCA_001593465
And two sets of reads:
http://www.ebi.ac.uk/ena/data/view/SRR1015747-SRR1015748
If we want to use the reads here we may need to investigate the difference between read sets. We should also check how they have assembled it. 
Does C. hominis also have 8 chromosome like C. parvum?

Simone: yes, C. hominis has 8 chromosomes, too. I will double check what we should retrieve for hominis.


Question 3: Is there any other parasite reference genomes that we wish to include? Please list them and also provide the accession numbers for them.
Simone: No, I think we should include the two above because are the best reconstruction of the genome, and we also have fresh transcriptomics data. Other genomes are only drafted.
Nima: Great thanks.
Question 4: What are the standard parameters that you wish to extract from this (A part from coverage)?
Simone: I think mapping is useful to estimate whether there is a bias in the sequencing experiments, i.e., if there are regions that are under-represented. Mapping data can also be used to visualize rearrangements. At least in the commercial software we have(CLC Genomics Workbench), mapping is used to call SNPs, because if one has all the sequences from one isolate mapped to a reference genome, then it is possible to exclude SNPs by selecting initial options (e.g., a minimum and/or maximum coverage,quality of the nucleotide and surrounding nucleotides, accounting for bias in the ratio forward/reverse reads, ecc) 

Nima: Yes that’s correct, it is needed for SNPs analysis.


Task 5: Comparative analysis of genomes based on SNPs (culminating into phylogenomics)     
The first step is clear here. The first step is to find all the SNPs for a given genome. Then we have possibly couple of options:
Question 1: What do we expect to get from SNPs analysis?
Simone: We should use SNPs for phylogenomics analysis, and we need to identify SNPs for the next step (genes under selection)
Question 2: Do we want to filter the SNPs? Is there any specific region of the genomes that we should have a closer look and look at the SNPs?
Simone: I will filter SNPs on the basis of th read quality (phred scores) and when coverage is abnormally high or low. We should look at the distribution of SNPs along the chromosomes to identify hot spots of variation, which are likely to be close to the telomeres and plot this in a good graphic format.

Nima: I don't know how we can do this, I think we should provide a result that can be opened with standard graphical softwares. We may be able also cluster the SNPs based on some physical location categorisations. I guess this is the kind of the case that we should figure out by doing it, so we do the SNPs and phylogeny and then decide how we can present the result to be more useful.
Simone: OK
We should create a plot number of SNPs versus the location in each genome. Then we should categorize them coding and non-coding part. 
Task 6: Comparative analysis for genes under selection pressure (through calculation of dN/dS ratio).
 Would you describe this? Please describe all the steps that need to happen.
Simone: First we should recall that we are comparing isolates from the same species or from very closely related species (homology between parvum and hominis is very high). This is important because the dN/dS ratio is meant to be used for analysis of species that diverged long time ago, and we should be cautious. 
Nevertheless, we should compute the frequency and distribution of synonymous and nonsynonymous substitutions for each gene and all isolates. My friends at University of Trento already developed a script that does this calculation starting from multiple alignments of all annotated genes of C. parvum.
In this way, we can easily detect very conserved genes (with no substitutions at all) on the one tail and highly variable ones on the other tail. Next we should look into the nature of those genes, and it will be valuable to have all genes assigned to functional categories in order to inspect if strongly conserved or strongly variable genes have a tendency to belong to specific categories. There are logical predictions here, but not based on genome-wide comparisons.
This sort of analysis will be contextualized in the current research for vaccine candidates too. 

Nima:  I don’t quite get how your friends have done it, I think we may need to talk about it in Skype. I write my understanding please correct it as you wish. 

Lets say you have set of annotated genomes of C. parvum. Then do you compare all genes against a reference genome, to first find the substitutions and then figure out if the SNPs is synonymous and nonsynonymous? After that you calculate the frequency of synonymous and nonsynonymous in a given gene in a given genome.
Simoen: what they did first was to de novo annotate each gene in each the genome, then cross this information with genes annotated in the reference genome to identify those that are present in all genomes (which corresponds to 99% or so). Then they generated multiple alignments for each gene (retaining also the physical position in the chromosomes), Last, they develop a script that scans for substitutions and is able to distinguish synonymous from nonsynonymous. So at the end they have a matrix of distances for each gene in each genome.

Based on your text I think your friends have done a multiple alignment and then for each gene you have the regions that you see different base and the region that all isolates have same base. For the region that they have different bases,  how do you decide which one is actually a substitution and which one is actually what it should be?  
Simone: I don’t think this is a big problem, but arbitrarily you can always decide that the reference genome is the “standard” nucleotide.

Ok lets say we have calculated the dN/dS for each gene. The first thing that we need is a threshold for classifying them into very conserved genes on the one tail and highly variable ones on the other tail. Based on your text you mentioned that very conserved genes are the genes with no substitutions at all. Do you mean the genes with no nonsynonymous substitutions shall be considered as very conserved genes? And in highly variable ones, what is your threshold for dN/dS. 
Simone: I believe there are very conserved genes, I should get the results from my friends very soon. To me, the “very” conserved genes will have no substitutions at all (synonymous or nonsynonymous), but when all genes will be ranked it will be easy to see what is the real situation (in the datasets we are looking at now).

After this classification we should get these two groups of genes and assign functional genes categorisation in each genes and then see how this functional annotation families are placed in variable and conserved genes group.  
Simone: I think we should check whether there are trends. For example, look if very variable genes code for proteins recognized by the host immune system (thus under positive selection to accumulate mutations) whereas very conserved ones code for structural proteins. But I would love to find things that do not fit with this scenario.    
Task 7: Comparative analysis specifically looking for structural rearrangements and recombination events.
Lets think we have a pipeline that gives all the structural rearrangements and recombination events in a given genome, what do we want to do with it? What do we want find here? Is there way to filter them? Or is there any question that we need to ask from the result of this analysis that we can program?            
Simone: here the main question is to understand how much recombination occurs and whether events are scattered randomly across the chromosomes or confined to specific regions. Thus, the first answer we want is the frequency and distribution of recombination events. I don’t know if you already have an idea of how to look systematically for recombination. One possibility is to build phylogenetic trees from all genes (ordered physically in the 8 chromosomes) and see if certain isolates cluster differently when one moves from one gene to the next. There are also other methods, I am keen to discuss this with you. 

Nima: I think we need to discuss this further. OK the main task is to calculate the frequency and distribution of  recombination events within the isolates and then look at the distributions within all the isolates. I think I need to explore this more and figure out how we should do it. It seems there are some standard techniques. I think we should look for similar research and task in different organism study and just do whatever others have done. If I find a paper that similar work has been done I pass to you, please do the same in case if you found similar thing. 
Simone: largely agree, we should not reinvent the wheel. This is a rather common question, and we can find inspiration and perhaps already available tools from the literature.
Task 8: Comparative analysis of hyper-variable regions (e.g., regions containing simple sequence repeats) with the goal of identifying markers useful for classical genotyping studies of isolates.                                                                                                     
Would you describe this? Please describe all the steps that need to happen. I think once you mentioned we should find all the repeats, what do we need to do with that? Imagine we find all the repeats region, what else shall we do with the result? What does it tell us? 
Simone: here we should start by recalling that what we know about population genetics of these parasites come from genotyping at loci containing simple repeats (mini- and micro-satellites). However, there is no consensus on which loci are more informative and the goal will be to have the smallest number while maintaining the discrimination power.
This is why it is important to identify those regions and then to look for variation among isolates.

Nima: Ok the first step is clear, we should find all the mini- and micro-satellites for all the isolates. I guess after that basically you would want to find the differences and variations among the isolates. And then what is this variation in mini- and micro-satellites can be translated to? I look at a human genome paper, and it seems that frequency of mini- and micro-satellites in some regions can lead to a disease. But in case of parasite what does this potentially tell us?
Simone: no, in parasites you don’t expect such a link. What we should do is use comparative genomics data (so, all the genome) to see which mini- or micro-satellites is more variable among the sequence genomes, guessing that these will be the real hypervariable ones (and if one design PCR primers and test other isolates, there will be genetic variability to exploit). This is really applied stuff, but it is of interest for those who need to type parasites in, e..g., outbreak situation or for molecular epidemiology. 
Task 9: Cluster analysis of samples originating from outbreaks, the goal being to define criteria useful to distinguish outbreak samples from unlinked, sporadic cases.
Would you describe this? Please describe all the steps that need to happen.

Simone: this comes from the work and objectives of WP4/7. Ideally, we would like to understand first how much variability exist among unrelated cases of cryptosporidiosis and to compare with the variability among clearly related (outbreak) cases.Can we define a threshold? Can we develop tools (algorithms) that can inform us about the relatedness of new cases? This is the scenario, but honestly, I don’t know how to translate this into a practical approach. I would suggest we get in touch with people from WP4/7 and see how they are approaching the question.

Nima: I think we need further discussion for this and as you mentioned we may need to involve others to see how they are doing this.
Simoen: Sure, there is a WP4/7 meeting on November 6 in Copenhagen. I will try to attend.


Any other analysis that you wish to be done?






Project TODO Actions
Create a volume in COMPARE-VM-2 for parasite
Move the fastq files into COMPARE-VM-2
Set up the quality control step

Project Accessories
Webinbox: 
Webin-44537

VM:
ubuntu@193.62.54.67

Datahub:

CLIMB: 
username
bryn:46_ENA
password
https://discourse.climb.ac.uk
https://bryn.climb.ac.uk
http://137.205.69.177
https://github.com/tseemann/nullarbor
https://stack.warwick.climb.ac.uk
Project Step Summary
In short (but I can think we need to discuss this more in depth), this is what I would like to do starting from raw NGS sequence data:
1) Trimming of the raw sequence
* trim_galore installation done.

* Fastqc done

* fastx_trimmer installation done
Libraries have been installed in:
   /usr/local/lib

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the `-LLIBDIR'
flag during linking and do at least one of the following:
   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable
     during execution
   - add LIBDIR to the `LD_RUN_PATH' environment variable
     during linking
   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag
   - have your system administrator add LIBDIR to `/etc/ld.so.conf'

See any operating system documentation about shared libraries for
2) Assembly (ideally, tests of different assemblers and selection of the best)
3) Reference mapping against annotated genomes (C. parvum and C. hominis), and calculation of standard parameters (e.g., coverage)
C. parvum has better annotation (paper)
C. hominis has better genomes (same papers)

get the availbale data for :
Cryptosporidium parvum
Taxonomy ID: 5807
and 
Cryptosporidium hominis
Taxonomy ID: 237895


I can do that without any issue. I have tools installed for this one. But would you point me to the annotated reference genomes of C. parvum and C. hominis?
And my understanding here is to map the reads from those 13 isolates to reference genomes and you are not talking about mapping the assemblies, am I correct? Or shall we do both of it? And also if you are interested to any other parameters than coverage let me know.
4) Comparative analysis of genomes based on SNPs (culminating into phylogenomics)
Here you want to SNP analysis against the mentioned reference genomes for all the 13 and
build the phylogenomics tree of all those 13 plus 2 references? plus the publically available ones.

The gene part that close to telomer are the most variable ones. And telemoer is where the recombinations events hapens a lot.
5) Comparative analysis for genes under selection pressure (through calculation of dN/dS ratio))

Do it based on a window of the genomes and then we can look at specific genes.

         

         My understanding is to do as follow but I might be completely wrong:
         1. Get the assemblies from step 2 and do functional gene annotation. 
         2. Then get the sequences of the genes.  
         3.  Align the genes against the reference genomes to find the SNPs. 
         4. Calculated number of silent and non-silent per genes and calculated dN/dS ratio per gene.
6) Comparative analysis specifically looking for structural rearrangements and recombination events
This is clear for me for now. There are standard tools and methods that people use for human genomes variation analysis and I can use them.
         
         The aim is to find out if the structural rearrangements and recombination events have happend outside the locus that already reported by many researcher. Is this can conclude and predict anything base don these events.
7) Comparative analysis of hyper-variable regions (e.g., regions containing simple sequence repeats) with the goal of identifying markers useful for classical genotyping studies of isolates.
Reapeat finder to use.
Some typing scheme based on repeat. We aim to find the most variable part of genomes cotaining the repeat. 

Need to discuss more.

8) Cluster analysis of samples originating from outbreaks, the goal being to define criteria useful to distinguish outbreak samples from unlinked, sporadic cases.
Average rate of variability need to be calculated.
outbreak clustring based some threshhold of difference.

In work package 4 and 7.

Sounds very interesting, and I possibly can use machine learning techniques for classifications. Basically my understanding here to be able discover important criteria that can lead to outbreaks and I think it would be very useful if we can develop a machine learning algorithm which can classify a sample as either outbreak or non-outbreak. But to do that how many samples do we have that we know it has created outbreak? And how many that haven’t created any out break? Basically we need to build a training dataset that we should use to train out algorithm and then a test data set to test out work.  Please let me know if you are looking for something else in 8.
Project technical notes
Project Scientific Notes
-about the genome itself: small (9 Mb), essentially composed of genes, quite rich in A+T (70%), organized in 8 linear chromosomes. Regions of very low complexity can be difficult to sequence and/or assemble.
-papers: attached are all NGS-based papers dealing with Crypto. As you see, not so many studies. I am sure you can orient yourself in the Materials and Methods to figure out who has used what in terms of bioinformatics analysis. But I will include this information in the document I am working on.


As you already indicate, we are currently working on databases that can be used for the identification of protozoa, and hopefully at some point also typing of specific lineagues.
So far we have been focusing on genomes, and have only touched upon gene-specific databases (18S rRNA genes, etc.) for sub-typing. This is work in progress, and we have a bioinformatics MSc student to support us in these efforts.

2016 strategy plan for protozoa (Cryptosporidium, Giardia) in COMPARE
State of the art
Information about genomes is still rather scarce for both groups of parasites. Recently, Casper has reviewed this for Cryptosporidium and identified a number of genome drafts deposited in GenBank (approximately 8 from C. parvum, 6 from C. hominis, 1 from C. muris, 1 from a chipmunk genotype), or at the Eukaryotic Pathogens Database (C. bailey, C. meleagridis) and at DDBJ (ERP001716 Pilot sequencing project of Cryptosporidium isolates, 43 drafts, not obvious to understand the source of isolates by visiting the webpage). 
There are more genomes likely to be released from a project in Sweden, and ongoing genome sequencing in the US (CDC) and elsewhere.
tax_tree(5806- Cryptosporidium)
Assemblies:

Sequences:
Sequence
Sequence (Update) (299)
Sequence (Release) (108,100)
Reads:


A snapshot of the methodology used in published NGS studies:
1)	Guo et al. analysed 24 different specimens and reported on 20 whole genome sequences from 6 different species. Both Roche 454 and Illumina (2x100 paired ends) methods were used. Assembly was done using CLC Genomics Workbench while for mapping of contigs to reference genomes they used MAUVE. The whole genome sequences are NOT available in public database, except for one isolate of the chipmunk genotype.
2)	Hadfield et al. analysed a number of clinical specimens to develop a method for oocyst puririfcation before NGS. They deposited 7 C. parvum and 3 C. hominis. All was based on Illumina (both Miseq and Hiseq) platform and Nextera-based libraries, so they have not used WGA. In terms of bio-informatics, they used CLC Genomics Workbench for de novo assembly, and CLC and Bowtie for read mapping. They further processed the de novo contigs from CLC by using a Post Assembly Genome Improvement Protocol (PAGIT). This consisted in ordering the scaffolds against the reference genome by ABACAS, a gap filling step by IMAGE, removal of single base errors and short indels by ICORN and finally transfer of the annotation of the reference genome by RATT.
3)	 Isaza et al. also focused on an improved annotation of C. parvum by sequencing full length cDNA libraries generated from oocyst and sporozoite mRNA. This new annotation mostly refined the exon-intron structure of a number of genes, but it is something to remember if we wish to update the annotation of the reference IOWA genome. In terms of genomics, they have used both 454 and Illumina to drat the genome of a C. hominis isolate from a HIV-positive woman. The genotype of this isolate was IeA11G3T3. The resulting genome was of 9.05 Mb in length, with a mean coverage of 68X, and 86 gaps. In terms of bio-informatics, they used Newbler for de novo assembly, and assigned the resulting contigs with ABACAS to pseudo-chromosomes using as reference C. parvum Iowa chromosomes. Reads were mapped using Bowtie. Some of the gaps were closed by 12 iterations of IMAGE. Transfer of the annotation of the reference genome by RATT.

ISS has generated four genome sequences (Illumina-based) of C. parvum isolates from animals. These genomes have been sequenced, after Whole Genome Amplification of genomic DNA from highly purified oocysts, at very high coverage (average more than 1000). Preliminary analyses of raw sequence data showed that 92 to 98% of the sequences mapped to the C. parvum reference genome, thus indicating that the overall procedure worked well. 
In this moment, other Cryptosporidium isolates (7 from animals, 2 from humans) and the first 8 Giardia duodenalis isolates are being sequenced, also after WGA and based on Illumina platform, this time using PCR free production of libraries. We plan to compare genomes drafts from WGA-amplified material and non-WGA from the same isolates to figure out what sort of bias and errors the WGA technique is introducing. We are actively looking for isolates, and have established good contacts with colleagues in EU and abroad. This should be source of interesting samples.
If we wish to start with Cryptosporidium, then we can use the genomes just mentioned above. 

What we need
As the available information is growing, and considering that bio-informatics pipelines that specifically deal with protozoan genomes are lacking, it is useful to discuss at least some of the features of such a pipeline:
1)	A tool for extracting SNPs from homologous genes, and then for running a phylogenetic analysis. This can be tested on the existing genomes.
2)	A tool for extracting defined markers (for Cryptosporidium: 18S rDNA, Hsp70, actin, GP60; for Giardia: 18S rDNA, beta-giardin, glutamate dehydrogenase, triose phosphate isomerase) that have been widely used in previous molecular typing of isolates. Note: to be effective, a database containing relevant information on the same markers needs to be developed (Casper already started with this).
3)	A tool that can extract sequences containing specific microsatellite repeats (at well-defined loci), count the number of repeats and assigned an allele code. Again, a database containing all known alleles at those loci needs to be developed. At the end, a matrix containing alleles codes at various loci can be generated and this information used to compare with existing data. Note: these regions are notoriously difficult to sequence.
4)	A tool that can compute non-synonymous versus synonymous substitutions in all homologous genes and generate a table of genes showing a dN/dS ratio over a defined threshold. Note: what genes are under positive selection pressure is essentially unknown.


Other important things:
•	To compare the performance of the different assemblers already present in the VM of Compare
•	More? Please express your opinion

A more general question that we should ask ourselves is: “What potential users of Compare would like to see in terms of data processing and analysis if they have raw sequence data from Cryptosporidium or Giardia (and in perspective, other parasites)?”
I think there is not a single answer, also because users may come from the clinical world, or be more interested in the environmental component (water), in food, or in outbreaks. As such, all of them may be interested in getting feedback about the quality of the data (e.g. coverage), but the exact type of outcome, and the pipeline behind, will need to be adapted considering the nature of the isolates and the reasons why these were studied by NGS.





Project background information

Homolog
A gene related to a second gene by descent from a common ancestral DNA sequence. The term, homolog, may apply to the relationship between genes separated by the event of speciation (see ortholog) or to the relationship betwen genes separated by the event of genetic duplication (see paralog).

Ortholog
Orthologs are genes in different species that evolved from a common ancestral gene by speciation. Normally, orthologs retain the same function in the course of evolution. Identification of orthologs is critical for reliable prediction of gene function in newly sequenced genomes. (See also Paralogs.).

Speciation
Speciation is the origin of a new species capable of making a living in a new way from the species from which it arose. As part of this process it has also aquired some barreir to genetic exchage with the parent species.

Paralog
Paralogs are genes related by duplication within a genome. Orthologs retain the same function in the course of evolution, whereas paralogs evolve new functions, even if these are related to the original one.

